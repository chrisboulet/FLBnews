#!/usr/bin/env python3
"""
Analyseur OpenRouter dÃ©diÃ© pour FLB News
Utilise GPT-5 pour gÃ©nÃ©rer des analyses et rÃ©sumÃ©s intelligents
"""

import os
import json
import logging
import time
from typing import Dict, List, Optional
from dataclasses import dataclass, field
import openai
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

@dataclass
class ArticleAnalysis:
    """RÃ©sultat d'analyse d'un article par GPT-5"""
    title_fr: str = ""
    smart_summary: str = ""  # RÃ©sumÃ© intelligent en franÃ§ais
    flb_relevance: str = ""  # Explication de la pertinence pour FLB
    business_impact: str = ""  # Impact sur le business
    recommended_actions: List[str] = field(default_factory=list)
    opportunities: List[str] = field(default_factory=list)
    risks: List[str] = field(default_factory=list)
    relevance_score: float = 0.0
    category: str = ""
    confidence: float = 0.0

class OpenRouterAnalyzer:
    """Analyseur utilisant OpenRouter avec GPT-4o"""
    
    def __init__(self, api_key: str = None, model: str = "openai/o4"):
        self.api_key = api_key or os.getenv('OPENROUTER_API_KEY')
        self.model = model
        self.client = None
        
        if self.api_key:
            self.client = openai.OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.api_key
            )
            logger.info(f"OpenRouter configurÃ© avec le modÃ¨le: {self.model}")
        else:
            logger.error("ClÃ© API OpenRouter non trouvÃ©e!")
    
    def analyze_article(self, title: str, content: str, source: str, url: str = "") -> ArticleAnalysis:
        """
        Analyser un article avec GPT-5 pour gÃ©nÃ©rer un rÃ©sumÃ© intelligent
        et une analyse stratÃ©gique pour FLB Solutions
        """
        
        if not self.client:
            return ArticleAnalysis(
                title_fr=title,
                smart_summary=content[:500] + "...",
                flb_relevance="Analyse non disponible"
            )
        
        # Prompt optimisÃ© pour GPT-5
        prompt = f"""Tu es un analyste stratÃ©gique expert pour FLB Solutions, distributeur alimentaire B2B de QuÃ©bec.
        
ARTICLE Ã€ ANALYSER:
Titre: {title}
Source: {source}
Contenu: {content[:2000]}

CONTEXTE FLB:
- Distributeur alimentaire B2B basÃ© Ã  QuÃ©bec
- Clients: restaurants, hÃ´tels, cafÃ©tÃ©rias, Ã©piceries
- Produits: frais, surgelÃ©s, Ã©picerie, viandes
- Zone: Capitale-Nationale et environs
- DÃ©fis: pÃ©nurie main-d'Å“uvre, inflation, chaÃ®ne d'approvisionnement

TÃ‚CHE: Analyser cet article et gÃ©nÃ©rer un JSON structurÃ©:

{{
    "title_fr": "Titre en franÃ§ais clair et accrocheur",
    "smart_summary": "RÃ©sumÃ© de 2-3 phrases expliquant les points clÃ©s pour un distributeur alimentaire",
    "flb_relevance": "Explication directe de pourquoi FLB doit s'intÃ©resser Ã  cette nouvelle",
    "business_impact": "Impact concret sur FLB (coÃ»ts, opportunitÃ©s, clients, etc.)",
    "category": "supply_chain|local|trends|regulatory|competitor|innovation|other",
    "relevance_score": 0-100,
    "opportunities": ["OpportunitÃ© business concrÃ¨te"],
    "risks": ["Risque potentiel"],
    "recommended_actions": ["Action spÃ©cifique que FLB devrait prendre"],
    "confidence": 0.1-1.0
}}

IMPORTANT: 
- RÃ©sumÃ© COURT et PERTINENT pour FLB
- Actions CONCRÃˆTES et RÃ‰ALISABLES
- RÃ©pondre UNIQUEMENT avec le JSON, sans texte additionnel"""

        try:
            logger.info(f"Analyse O4 de: {title[:50]}...")
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "Tu es un analyste expert en distribution alimentaire. RÃ©ponds UNIQUEMENT en JSON valide."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # Plus dÃ©terministe
                max_tokens=800,  # RÃ©duit pour Ã©conomiser les tokens
                timeout=15,  # Timeout pour Ã©viter les attentes infinies
                extra_headers={
                    "HTTP-Referer": "http://localhost:3000",
                    "X-Title": "FLB News Bulletin Generator"
                }
            )
            
            processing_time = time.time() - start_time
            logger.info(f"RÃ©ponse reÃ§ue en {processing_time:.2f}s")
            
            # Parser la rÃ©ponse
            response_text = response.choices[0].message.content
            
            # Nettoyer et parser le JSON
            try:
                # Extraire le JSON de la rÃ©ponse
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    data = json.loads(json_match.group())
                else:
                    data = json.loads(response_text)
                
                # CrÃ©er l'objet d'analyse
                return ArticleAnalysis(
                    title_fr=data.get('title_fr', title),
                    smart_summary=data.get('smart_summary', content[:300] + "..."),
                    flb_relevance=data.get('flb_relevance', 'Pertinence Ã  Ã©valuer'),
                    business_impact=data.get('business_impact', ''),
                    recommended_actions=data.get('recommended_actions', [])[:3],
                    opportunities=data.get('opportunities', [])[:2],
                    risks=data.get('risks', [])[:2],
                    relevance_score=float(data.get('relevance_score', 50)) / 100,
                    category=data.get('category', 'other'),
                    confidence=float(data.get('confidence', 0.5))
                )
                
            except (json.JSONDecodeError, KeyError) as e:
                logger.error(f"Erreur parsing JSON: {e}")
                logger.debug(f"RÃ©ponse brute: {response_text[:500]}...")
                
                # Fallback avec analyse basique
                return ArticleAnalysis(
                    title_fr=title,
                    smart_summary=f"Article de {source} sur les dÃ©veloppements rÃ©cents du secteur alimentaire.",
                    flb_relevance="Article potentiellement pertinent pour FLB Solutions.",
                    relevance_score=0.5,
                    category="other",
                    confidence=0.3
                )
                
        except Exception as e:
            logger.error(f"Erreur OpenRouter: {e}")
            return ArticleAnalysis(
                title_fr=title,
                smart_summary=content[:300] + "...",
                flb_relevance="Analyse temporairement indisponible",
                relevance_score=0.3
            )
    
    def analyze_batch(self, articles: List[Dict], max_articles: int = 7) -> List[ArticleAnalysis]:
        """
        Analyser un lot d'articles avec O4 de maniÃ¨re optimisÃ©e
        Utilise un retry intelligent et Ã©vite les pauses fixes
        """
        results = []
        
        # PrÃ©-trier les articles par score de pertinence si disponible
        # Buffer: analyser plus d'articles pour avoir des alternatives si certains Ã©chouent
        buffer_size = max_articles + 3  # 3 articles de buffer
        candidate_articles = articles[:max_articles * 2] if len(articles) > max_articles * 2 else articles
        
        sorted_articles = sorted(
            candidate_articles,
            key=lambda x: x.get('relevance_score', 0),
            reverse=True
        )[:buffer_size]
        
        logger.info(f"Buffer d'analyse: {len(sorted_articles)} articles candidats (cible: {max_articles})")
        
        for i, article in enumerate(sorted_articles):
            logger.info(f"Analyse O4 ({i+1}/{len(sorted_articles)}): {article.get('title', '')[:50]}...")
            
            # Analyser avec retry intelligent
            analysis = self._analyze_with_retry(
                title=article.get('title', ''),
                content=article.get('summary', '') + " " + article.get('full_text', '')[:1000],
                source=article.get('source', ''),
                url=article.get('url', ''),
                retry_count=3
            )
            
            results.append(analysis)
            
            # ArrÃªter si on a assez d'analyses rÃ©ussies
            successful_analyses = [r for r in results if r.relevance_score > 0.1]  # Score minimum
            if len(successful_analyses) >= max_articles:
                logger.info(f"Objectif atteint: {len(successful_analyses)} analyses rÃ©ussies")
                break
        
        logger.info(f"Analyse terminÃ©e: {len(results)} articles traitÃ©s, {len([r for r in results if r.relevance_score > 0.1])} rÃ©ussis")
        return results[:max_articles]  # Retourner seulement le nombre demandÃ©
    
    def _analyze_with_retry(self, title: str, content: str, source: str, url: str = "", retry_count: int = 3) -> ArticleAnalysis:
        """
        Analyser avec retry intelligent et backoff exponentiel
        """
        last_error = None
        
        for attempt in range(retry_count):
            try:
                return self.analyze_article(title, content, source, url)
            except Exception as e:
                last_error = e
                if attempt < retry_count - 1:
                    # Backoff exponentiel: 1s, 2s, 4s
                    wait_time = 2 ** attempt
                    logger.warning(f"API error (attempt {attempt + 1}), retrying in {wait_time}s: {str(e)}")
                    time.sleep(wait_time)
                else:
                    logger.error(f"All retry attempts failed for {title[:30]}...")
        
        # Fallback si tous les essais Ã©chouent
        logger.warning(f"Falling back to basic analysis for: {title[:50]}...")
        return ArticleAnalysis(
            title_fr=title,
            smart_summary=content[:300] + "...",
            flb_relevance="Analyse temporairement indisponible - article sÃ©lectionnÃ© par scoring automatique",
            relevance_score=0.6,  # Score conservateur
            category="other",
            confidence=0.3
        )

def test_analyzer():
    """Test de l'analyseur OpenRouter"""
    
    analyzer = OpenRouterAnalyzer()
    
    test_article = {
        'title': "PÃ©nurie de camionneurs : Metro et Sobeys peinent Ã  approvisionner le QuÃ©bec",
        'summary': """Les grandes chaÃ®nes d'alimentation du QuÃ©bec font face Ã  des dÃ©fis majeurs 
        d'approvisionnement. La pÃ©nurie de camionneurs affecte particuliÃ¨rement la rÃ©gion de 
        la Capitale-Nationale. Les restaurants et hÃ´tels peinent Ã  obtenir des produits frais 
        rÃ©guliÃ¨rement. Les coÃ»ts de transport ont augmentÃ© de 35% en 6 mois.""",
        'source': "La Presse",
        'url': "https://example.com/test"
    }
    
    print("ðŸ§ª Test de l'analyseur OpenRouter O4")
    print("="*60)
    
    analysis = analyzer.analyze_article(
        title=test_article['title'],
        content=test_article['summary'],
        source=test_article['source'],
        url=test_article['url']
    )
    
    print(f"\nðŸ“° Titre FR: {analysis.title_fr}")
    print(f"\nðŸ’¡ RÃ©sumÃ© intelligent:\n   {analysis.smart_summary}")
    print(f"\nðŸŽ¯ Pertinence FLB:\n   {analysis.flb_relevance}")
    print(f"\nðŸ’¼ Impact business:\n   {analysis.business_impact}")
    
    if analysis.opportunities:
        print(f"\nâœ… OpportunitÃ©s:")
        for opp in analysis.opportunities:
            print(f"   - {opp}")
    
    if analysis.risks:
        print(f"\nâš ï¸ Risques:")
        for risk in analysis.risks:
            print(f"   - {risk}")
    
    if analysis.recommended_actions:
        print(f"\nðŸ“‹ Actions recommandÃ©es:")
        for action in analysis.recommended_actions:
            print(f"   - {action}")
    
    print(f"\nðŸ“Š Score: {analysis.relevance_score:.0%} | CatÃ©gorie: {analysis.category}")
    print(f"ðŸ” Confiance: {analysis.confidence:.0%}")

if __name__ == "__main__":
    test_analyzer()